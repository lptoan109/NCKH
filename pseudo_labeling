import tensorflow as tf                      # Th∆∞ vi·ªán ch√≠nh ƒë·ªÉ load m√¥ h√¨nh v√† x·ª≠ l√Ω ·∫£nh
import numpy as np                           # X·ª≠ l√Ω ma tr·∫≠n, vector
import os                                    # L√†m vi·ªác v·ªõi h·ªá th·ªëng file/th∆∞ m·ª•c
import shutil                                # ƒê·ªÉ copy file
from tensorflow.keras.preprocessing import image  # Ti·ªán √≠ch load ·∫£nh v√† chuy·ªÉn sang tensor
from tqdm import tqdm                        # Hi·ªÉn th·ªã ti·∫øn ƒë·ªô (progress bar)

# === üîß C·∫§U H√åNH ===
IMG_SIZE = (128, 128)  # K√≠ch th∆∞·ªõc ·∫£nh ƒë·∫ßu v√†o ph√π h·ª£p v·ªõi EfficientNet
MODEL_PATH = r"G:\My Drive\T√†i li·ªáu NCKH\AIData\efficientnet_cough_model_20250620_1830.keras"  # ‚úÖ ƒê∆∞·ªùng d·∫´n ƒë·∫øn file m√¥ h√¨nh .keras ƒë√£ hu·∫•n luy·ªán
UNLABELED_DIR = r"D:\DuLieuHo\unlabeled_23000"  # ‚úÖ Th∆∞ m·ª•c ch·ª©a ·∫£nh ch∆∞a c√≥ nh√£n (·∫£nh spectrogram .png)
OUTPUT_DIR = r"D:\DuLieuHo\pseudo_label"         # ‚úÖ Th∆∞ m·ª•c l∆∞u ·∫£nh ƒë√£ g√°n nh√£n theo class
CONFIDENCE_THRESHOLD = 0.9                       # ‚úÖ Ch·ªâ g√°n nh√£n cho ·∫£nh c√≥ ƒë·ªô t·ª± tin cao h∆°n ng∆∞·ª°ng n√†y

# === üì¶ LOAD M√î H√åNH ƒê√É HU·∫§N LUY·ªÜN ===
model = tf.keras.models.load_model(MODEL_PATH)   # T·∫£i m√¥ h√¨nh t·ª´ file .keras

# L·∫•y t√™n c√°c l·ªõp t·ª´ th∆∞ m·ª•c train c≈© ƒë·ªÉ d√πng l√†m nh√£n
class_names = os.listdir(os.path.join(r"D:\DuLieuHo\dataset", "train"))
class_names.sort()                               # S·∫Øp x·∫øp ƒë·ªÉ ƒë·∫£m b·∫£o ƒë√∫ng th·ª© t·ª± nh√£n
print("üìÇ L·ªõp m√¥ h√¨nh:", class_names)

# === üìÅ T·∫†O C√ÅC TH∆Ø M·ª§C ƒê·∫¶U RA THEO NH√ÉN D·ª∞ ƒêO√ÅN ===
for cls in class_names:
    os.makedirs(os.path.join(OUTPUT_DIR, cls), exist_ok=True)  # T·∫°o folder n·∫øu ch∆∞a t·ªìn t·∫°i

# === üîÅ DUY·ªÜT QUA T·∫§T C·∫¢ ·∫¢NH CH∆ØA NH√ÉN ===
for fname in tqdm(os.listdir(UNLABELED_DIR)):   # Hi·ªÉn th·ªã ti·∫øn ƒë·ªô v·ªõi tqdm
    if not fname.endswith('.png'):              # B·ªè qua file kh√¥ng ph·∫£i ·∫£nh PNG
        continue

    fpath = os.path.join(UNLABELED_DIR, fname)  # ƒê∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß t·ªõi ·∫£nh

    # Load ·∫£nh v√† resize ƒë√∫ng k√≠ch th∆∞·ªõc
    img = image.load_img(fpath, target_size=IMG_SIZE)
    img_array = image.img_to_array(img) / 255.0         # Chuy·ªÉn th√†nh tensor v√† scale v·ªÅ [0,1]
    img_array = np.expand_dims(img_array, axis=0)       # Th√™m chi·ªÅu batch: (1, 128, 128, 3)

    # D·ª± ƒëo√°n nh√£n b·∫±ng m√¥ h√¨nh
    preds = model.predict(img_array, verbose=0)[0]      # K·∫øt qu·∫£: m·∫£ng x√°c su·∫•t (v√≠ d·ª•: [0.02, 0.95, 0.03])
    max_prob = np.max(preds)                            # X√°c su·∫•t cao nh·∫•t
    predicted_label = class_names[np.argmax(preds)]     # L·∫•y nh√£n t∆∞∆°ng ·ª©ng v·ªõi x√°c su·∫•t cao nh·∫•t

    # N·∫øu m√¥ h√¨nh t·ª± tin ƒë·ªß (tr√™n ng∆∞·ª°ng), th√¨ m·ªõi l∆∞u ·∫£nh v√†o folder t∆∞∆°ng ·ª©ng
    if max_prob >= CONFIDENCE_THRESHOLD:
        out_path = os.path.join(OUTPUT_DIR, predicted_label, fname)
        shutil.copy(fpath, out_path)                    # Copy file ·∫£nh v√†o th∆∞ m·ª•c ƒë√∫ng class

print("‚úÖ Ho√†n t·∫•t g√°n nh√£n gi·∫£. B·∫°n c√≥ th·ªÉ d√πng folder pseudo_label ƒë·ªÉ train ti·∫øp.")
