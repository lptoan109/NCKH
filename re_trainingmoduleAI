import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.applications import EfficientNetB0
import matplotlib.pyplot as plt
import pandas as pd
import os
from datetime import datetime

# ====== ğŸ”§ Cáº¤U HÃŒNH ======
IMG_SIZE = (128, 128)                            # KÃ­ch thÆ°á»›c áº£nh Ä‘áº§u vÃ o cá»§a máº¡ng
BATCH_SIZE = 32                                  # Sá»‘ lÆ°á»£ng áº£nh má»—i batch
EPOCHS = 15                                      # Sá»‘ epoch cho fine-tuning
COMBINED_TRAIN_DIR = r"D:\DuLieuHo\combined_train"   # ğŸ“ ThÆ° má»¥c chá»©a dá»¯ liá»‡u Ä‘Ã£ trá»™n (gá»‘c + pseudo)
VAL_DIR = r"D:\DuLieuHo\dataset\val"                  # ğŸ“ Táº­p validation ban Ä‘áº§u
MODEL_INPUT = r"G:\My Drive\TÃ i liá»‡u NCKH\AIData\efficientnet_cough_model_20250620_1830.keras"  # âœ… MÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n trÆ°á»›c Ä‘Ã³
OUTPUT_FOLDER = r"G:\My Drive\TÃ i liá»‡u NCKH\AIData"      # ğŸ“ NÆ¡i lÆ°u log, biá»ƒu Ä‘á»“, mÃ´ hÃ¬nh má»›i
MODEL_NAME = "efficientnet_cough_finetune"               # ğŸ“› TÃªn mÃ´ hÃ¬nh

# ====== ğŸ“‚ Táº¢I Dá»® LIá»†U ======
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    COMBINED_TRAIN_DIR,                         # Load áº£nh tá»« combined_train
    image_size=IMG_SIZE,                        # Resize áº£nh
    batch_size=BATCH_SIZE                       # Batch size
)
val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    VAL_DIR,                                    # Load áº£nh validation cÅ©
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE
)

class_names = train_ds.class_names              # Láº¥y tÃªn cÃ¡c class
num_classes = len(class_names)                  # Äáº¿m sá»‘ lá»›p
print("ğŸ“‚ Lá»›p:", class_names)

# ====== âš™ï¸ PREFETCH GIÃšP TÄ‚NG HIá»†U NÄ‚NG TRAINING ======
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.prefetch(AUTOTUNE)
val_ds = val_ds.prefetch(AUTOTUNE)

# ====== ğŸ§  LOAD MÃ” HÃŒNH ÄÃƒ HUáº¤N LUYá»†N Láº¦N 1 ======
model = tf.keras.models.load_model(MODEL_INPUT)  # Load mÃ´ hÃ¬nh .keras Ä‘Ã£ huáº¥n luyá»‡n trÆ°á»›c
print("âœ… ÄÃ£ load mÃ´ hÃ¬nh:", MODEL_INPUT)

# ====== ğŸ”“ Má» KHÃ“A CÃC Táº¦NG Äá»‚ FINE-TUNE ======
base_model = model.layers[1]                     # EfficientNetB0 lÃ  layer thá»© 2 trong mÃ´ hÃ¬nh Sequential
base_model.trainable = True                      # Cho phÃ©p huáº¥n luyá»‡n láº¡i

# â„ï¸ ÄÃ³ng bÄƒng khoáº£ng 70% táº§ng Ä‘áº§u tiÃªn Ä‘á»ƒ trÃ¡nh overfitting
FINE_TUNE_AT = int(len(base_model.layers) * 0.7)
for layer in base_model.layers[:FINE_TUNE_AT]:
    layer.trainable = False

# ====== ğŸ” COMPILE Láº I MÃ” HÃŒNH ======
model.compile(
    optimizer=tf.keras.optimizers.Adam(1e-5),    # DÃ¹ng learning rate tháº¥p Ä‘á»ƒ fine-tune nháº¹ nhÃ ng
    loss='sparse_categorical_crossentropy',      # DÃ¹ng cho nhÃ£n dáº¡ng sá»‘ (int)
    metrics=['accuracy']
)

# ====== ğŸš€ TIáº¾N HÃ€NH FINE-TUNE ======
history_finetune = model.fit(
    train_ds,                      # Dá»¯ liá»‡u huáº¥n luyá»‡n (gá»‘c + pseudo)
    validation_data=val_ds,        # Dá»¯ liá»‡u Ä‘Ã¡nh giÃ¡
    epochs=EPOCHS                  # Sá»‘ vÃ²ng láº·p
)

# ====== ğŸ“ˆ GHI LOG & Váº¼ BIá»‚U Äá»’ ======
def save_training_log(history, output_folder=OUTPUT_FOLDER, prefix=MODEL_NAME):
    hist = history.history                                     # Láº¥y lá»‹ch sá»­ training
    df = pd.DataFrame({                                        # Táº¡o DataFrame Ä‘á»ƒ xuáº¥t Excel
        'Epoch': list(range(1, len(hist['accuracy']) + 1)),
        'Accuracy': hist['accuracy'],
        'Loss': hist['loss'],
        'Val Accuracy': hist['val_accuracy'],
        'Val Loss': hist['val_loss']
    })

    os.makedirs(output_folder, exist_ok=True)                  # Táº¡o thÆ° má»¥c náº¿u chÆ°a cÃ³
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")       # Gáº¯n timestamp Ä‘á»ƒ phÃ¢n biá»‡t
    excel_path = os.path.join(output_folder, f"{prefix}_finetune_log_{timestamp}.xlsx")
    acc_plot = os.path.join(output_folder, f"{prefix}_finetune_acc_{timestamp}.png")
    loss_plot = os.path.join(output_folder, f"{prefix}_finetune_loss_{timestamp}.png")

    df.to_excel(excel_path, index=False)                       # LÆ°u log dÆ°á»›i dáº¡ng Excel
    print("âœ… ÄÃ£ lÆ°u log:", excel_path)

    # ğŸ¯ Accuracy Plot
    plt.figure(figsize=(8, 5))
    plt.plot(df['Epoch'], df['Accuracy'], label='Train Acc')
    plt.plot(df['Epoch'], df['Val Accuracy'], label='Val Acc')
    plt.title('Accuracy theo Epoch')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.grid()
    plt.legend()
    plt.tight_layout()
    plt.savefig(acc_plot)
    plt.close()
    print("âœ… ÄÃ£ lÆ°u biá»ƒu Ä‘á»“ Accuracy:", acc_plot)

    # ğŸ¯ Loss Plot
    plt.figure(figsize=(8, 5))
    plt.plot(df['Epoch'], df['Loss'], label='Train Loss')
    plt.plot(df['Epoch'], df['Val Loss'], label='Val Loss')
    plt.title('Loss theo Epoch')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.grid()
    plt.legend()
    plt.tight_layout()
    plt.savefig(loss_plot)
    plt.close()
    print("âœ… ÄÃ£ lÆ°u biá»ƒu Ä‘á»“ Loss:", loss_plot)

# Ghi log ra file Excel + áº£nh biá»ƒu Ä‘á»“
save_training_log(history_finetune)

# ====== ğŸ’¾ LÆ¯U MÃ” HÃŒNH FINE-TUNED ======
model_path = os.path.join(OUTPUT_FOLDER, f"{MODEL_NAME}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.keras")
model.save(model_path)                        # LÆ°u mÃ´ hÃ¬nh má»›i á»Ÿ Ä‘á»‹nh dáº¡ng .keras
print("âœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh fine-tuned:", model_path)
